# CPU 코어 간 컨텍스트 스위칭이 많다고 판단은 어떻게?
CPU 코어 간 컨텍스트 스위칭이 많다는 판단은 시스템의 성능 모니터링 툴과 운영체제의 통계 정보를 통해 알 수 있습니다. 컨텍스트 스위칭이 많다는 것은 CPU가 프로세스 간의 상태를 자주 전환해야 하므로 성능 저하가 발생할 가능성이 크기 때문입니다.

🔹 컨텍스트 스위칭 모니터링 방법
vmstat (Virtual Memory Statistics)

리눅스에서 vmstat 명령어를 사용하면 시스템의 컨텍스트 스위칭 관련 정보를 볼 수 있습니다. vmstat는 시스템의 메모리, 프로세스, CPU 상태를 모니터링합니다.
bash
vmstat 1
vmstat 출력의 주요 항목:
cs (context switches): 시스템에서 발생한 컨텍스트 스위칭의 수.
r (running processes): 실행 중인 프로세스 수.
b (blocked processes): 차단된 프로세스 수.
컨텍스트 스위칭이 많다는 것을 판단하려면 cs 값이 비정상적으로 높다면 그만큼 CPU 간의 컨텍스트 스위칭이 자주 발생한다고 볼 수 있습니다.

mpstat (Multiprocessor Statistics)

mpstat 명령어는 멀티코어 시스템에서 CPU 코어 간의 성능 통계를 제공합니다. 특히 각 CPU 코어의 사용률, 상태 등을 확인할 수 있습니다.
bash
mpstat -P ALL 1
mpstat의 주요 항목:
intr/s (interrupts per second): 하드웨어 인터럽트 및 소프트웨어 인터럽트의 수.
cpu (user, system, idle): 각 CPU 코어에서의 사용자 프로세스, 시스템 프로세스, 유휴 상태 비율.
높은 인터럽트 비율과 낮은 유휴 시간은 시스템이 많은 작업을 처리하고 있거나, 과도한 컨텍스트 스위칭을 유발하는 작업이 있을 가능성을 시사합니다.

pidstat

**pidstat**는 각 프로세스 별로 CPU 사용률, I/O 작업, 컨텍스트 스위칭 등을 추적할 수 있는 도구입니다.
bash
pidstat -w 1
pidstat -w는 각 프로세스가 하나의 CPU에서 다른 CPU로 전환되는 컨텍스트 스위칭 횟수를 추적합니다. 이 값이 비정상적으로 높다면, 프로세스 간의 자주 변경되는 CPU 상태를 알 수 있습니다.
dstat

**dstat**는 시스템의 다양한 리소스를 동시에 모니터링할 수 있는 도구입니다. 이를 통해 컨텍스트 스위칭, CPU 사용률, 메모리 사용량 등을 동시에 볼 수 있습니다.
bash
dstat -c --cpu --w
/proc 파일 시스템

/proc 디렉토리 내에서 컨텍스트 스위칭 정보를 확인할 수 있습니다.
/proc/stat: 시스템의 전체적인 컨텍스트 스위칭 정보를 제공합니다.
procs_running(실행 중인 프로세스 수)
procs_blocked(차단된 프로세스 수)
ctxt(전체 시스템에서 발생한 컨텍스트 스위칭 횟수)
/proc/[pid]/stat: 특정 프로세스의 컨텍스트 스위칭 통계를 확인할 수 있습니다.
예를 들어:

bash
cat /proc/stat | grep ctxt
이 명령은 시스템에서 발생한 전체 컨텍스트 스위칭 횟수를 출력합니다. 이 값이 비정상적으로 높다면 컨텍스트 스위칭이 많이 발생하고 있다는 신호입니다.

🔹 컨텍스트 스위칭이 많은 경우 나타나는 증상
CPU 과부하:

프로세스가 자주 상태를 전환해야 하므로, CPU가 과부하 상태가 되며 성능 저하가 발생할 수 있습니다.
메모리 캐시 미스 증가:

자주 컨텍스트 스위칭이 발생하면 캐시에서 데이터를 가져오는 빈도가 늘어나 캐시 미스가 증가할 수 있습니다. 이는 메모리 접근 시간이 길어지게 하여 성능을 떨어뜨립니다.
프로세스 응답 지연:

프로세스가 자주 중단되고 다시 시작되기 때문에, 응답 시간이 증가할 수 있습니다.
🔹 컨텍스트 스위칭 과다 발생 원인
많은 수의 프로세스 실행: 너무 많은 프로세스가 동시에 실행되면, 자주 CPU 간에 컨텍스트 스위칭이 발생할 수 있습니다.
비효율적인 멀티스레딩: 적절한 CPU 코어 할당 없이 프로세스가 계속해서 다른 코어로 이동하면 컨텍스트 스위칭이 자주 발생합니다.
I/O 작업: I/O 작업이 많으면, CPU가 기다리는 동안 컨텍스트 스위칭이 발생할 수 있습니다.
상호 배제(mutex, lock)와 같은 동기화 작업: 프로세스 간의 경쟁 상태나 자원 대기 시간으로 인해 자주 CPU가 변경될 수 있습니다.
🔹 컨텍스트 스위칭 과다 해결 방안
CPU Affinity 사용:

프로세스들이 특정 CPU에서 실행되도록 affinity를 설정하여 불필요한 코어 간 이동을 줄입니다.
프로세스 최적화:

필요 이상의 프로세스를 실행하지 않도록 하고, 멀티스레딩을 사용할 경우 스레드 수와 CPU 코어 수를 잘 맞추는 것이 중요합니다.
I/O 최적화:

I/O 작업이 많다면, 이를 최소화하거나 비동기 I/O 처리를 고려합니다.
Lock-Free 알고리즘 사용:

동기화가 필요한 작업에서 Lock-Free 알고리즘을 사용하여 자원 경쟁을 최소화합니다.
🔹 결론
컨텍스트 스위칭이 많다고 판단하는 방법은 vmstat, mpstat, pidstat, /proc/stat 등 다양한 도구와 명령어를 통해 확인할 수 있습니다. 이를 통해 컨텍스트 스위칭 횟수가 비정상적으로 높다면, CPU와 메모리 자원의 과도한 사용을 줄이기 위한 최적화가 필요하다는 것을 알 수 있습니다.


# cpu idle 이 95% 이상인데도 CPU 과부하가 나오는 경우
CPU idle이 95% 이상인데도 CPU 과부하가 발생하는 경우는 시스템의 자원 사용이 CPU 외에 다른 요소에 의해서 영향을 받을 때 발생할 수 있습니다. 즉, CPU는 유휴 상태에 있지만 메모리, I/O, 네트워크, 디스크와 같은 다른 자원들이 병목을 일으키고 있기 때문에 CPU 과부하처럼 보일 수 있습니다. 이런 현상은 다음과 같은 원인들로 발생할 수 있습니다:

1. I/O 병목 (Input/Output Bottleneck)
디스크 I/O, 네트워크 I/O, 혹은 기타 외부 장치와의 통신이 너무 느려서 시스템이 대기 상태에 빠지는 경우가 발생할 수 있습니다. 
CPU가 유휴 상태에 있을 때도, I/O 작업이 완료되기를 기다리며 시스템이 병목 상태에 빠질 수 있습니다.
예: 디스크에서 데이터를 읽거나 네트워크에서 데이터를 받기 위해 대기 중일 때, CPU는 작업을 처리하지 않지만, 시스템이 응답 속도에서 병목을 경험할 수 있습니다.
2. 메모리 부족 (Memory Bottleneck)
메모리 부족 또는 **스와핑(swap)**이 발생하면, 시스템이 디스크를 사용하여 메모리 부족을 보충하려고 시도하면서 성능 저하가 발생할 수 있습니다. 
이는 CPU 사용률이 낮더라도 시스템 응답 속도가 느려지거나 병목이 발생하는 상황을 만들 수 있습니다.
스와핑이 발생하면 메모리와 디스크 간에 빈번한 데이터 이동이 이루어지기 때문에 CPU는 상대적으로 유휴 상태여도 성능 저하가 심각할 수 있습니다.
vmstat를 사용하여 메모리 사용 상태를 확인하고, si (swap in), so (swap out) 값이 높다면, 스와핑이 발생하고 있다는 신호일 수 있습니다.
3. 컨텍스트 스위칭 과다
과도한 컨텍스트 스위칭이 발생할 때도 CPU는 상대적으로 유휴 상태로 보일 수 있습니다. 
이때 프로세스 간 빈번한 상태 전환이 이루어져, CPU는 각 프로세스를 처리하려고 하지만, 시스템 전체의 성능 저하를 초래할 수 있습니다.
컨텍스트 스위칭이 많으면 시스템 자원의 효율적인 사용을 방해하고, 결국 CPU의 사용 효율성을 떨어뜨려 과부하처럼 보일 수 있습니다.
4. 스케줄러 및 우선순위 문제
스케줄러가 적절한 CPU 자원 분배를 하지 못하거나, 프로세스의 우선순위가 잘못 설정되어 CPU가 일부 작업을 처리하는 데 비효율적일 수 있습니다. 
이 경우 CPU는 유휴 상태일 수 있지만, 다른 작업들이 실행되기 위해 대기하면서 성능이 저하될 수 있습니다.
5. 락 경합 (Lock Contention)
동기화 문제로 인해 다수의 프로세스나 스레드가 동일한 자원을 접근하려고 시도하는 경우, 락 경합이 발생합니다. 
이로 인해 프로세스가 블록되거나 대기 상태에 빠질 수 있으며, 실제로 CPU가 사용되지 않더라도 시스템은 비효율적으로 동작할 수 있습니다.
락 경합을 해결하지 않으면, CPU 사용률은 낮고 시스템 성능은 저하되는 상호 배제 문제에 직면할 수 있습니다.
6. 멀티스레딩/멀티프로세스 스케일링 문제
멀티스레딩 또는 멀티프로세스 애플리케이션이 CPU 코어에 잘 배분되지 않거나, 작업을 분배하는 데 비효율적일 경우, CPU 사용률은 낮지만 처리 속도가 느려지고, 시스템은 병목 상태에 빠질 수 있습니다.
예를 들어, 프로세스가 너무 많이 fork되거나, 각 스레드가 지나치게 자원을 차지하여 병목을 유발할 수 있습니다.
7. 네트워크 대기 시간 (Network Latency)
네트워크 대기 시간으로 인해 TCP/IP 프로토콜의 지연이나 패킷 손실 등이 발생하면, CPU는 대기 상태에 있어도 애플리케이션의 성능이 저하될 수 있습니다.
네트워크 관련 작업이 대기 중일 때 CPU는 사용하지 않지만, 애플리케이션의 응답 시간이 늘어나는 결과를 초래할 수 있습니다.
8. 저장소 성능 문제 (Storage Performance Issues)
디스크 속도나 스토리지 시스템이 느릴 경우, CPU는 대기 상태일 수 있지만 시스템 성능은 크게 저하될 수 있습니다. 
특히 디스크 I/O가 많은 작업이 있을 경우, CPU는 유휴 상태로 보이지만 디스크 작업이 병목이 되어 성능에 영향을 미칩니다.
🔹 이 문제를 해결하는 방법
iostat, vmstat, mpstat 사용:

디스크 I/O, 메모리, CPU 사용률 등을 확인하여 병목이 발생하는 자원을 파악합니다.
iostat와 vmstat로 디스크와 메모리 상태를 확인하고, 스와핑이 일어나는지, 디스크 대기 시간이 긴지 등을 점검합니다.
top 또는 htop 사용:

top 또는 htop 명령어를 사용하여 실시간 프로세스와 시스템 자원 사용을 모니터링하고, CPU 사용률 외에도 메모리와 I/O가 높은 프로세스를 확인합니다.
I/O 최적화:

디스크 및 네트워크 I/O가 병목의 원인이라면, 디스크 속도를 개선하거나 I/O 작업을 비동기식으로 처리할 수 있습니다.
메모리 최적화:

스와핑을 줄이기 위해 시스템에서 사용 가능한 메모리 용량을 늘리거나, 메모리 풀을 효율적으로 관리하여 메모리 병목을 해결합니다.
락 경합 및 스케줄링 개선:

락 경합을 피하고 스레드 또는 프로세스의 스케줄링을 효율적으로 조정하여 CPU 자원을 적절하게 배분합니다.
프로세스와 스레드 수 최적화:

프로세스 수나 스레드 수를 최적화하여 시스템의 자원 사용을 효율적으로 관리합니다.
🔹 결론
CPU idle이 95% 이상이라도 디스크 I/O, 메모리 부족, 락 경합, 네트워크 대기 시간 등 다른 자원에서 병목이 발생하면 CPU 과부하처럼 보일 수 있습니다. 
모니터링 도구를 사용하여 시스템의 병목 지점을 정확히 파악하고, 해당 자원을 최적화하는 방식으로 문제를 해결할 수 있습니다.


# affinity 할당하면 성능이 얼마나 올라갈것으로 예상되?
CPU affinity를 설정하면 성능 향상 효과가 있을 수 있지만, 그 효과는 다양한 요소에 따라 다를 수 있습니다. 특히, 성능 향상 정도는 다음과 같은 주요 요인에 의해 결정됩니다:

🔹 성능 향상 요인
CPU 캐시 지역성:

**캐시 지역성(Locality)**은 성능 향상의 중요한 요소입니다. 프로세스가 같은 CPU 코어에서 실행되면, 해당 코어의 **캐시(L1, L2, L3)**를 재사용할 수 있습니다. CPU는 캐시에서 데이터를 가져오는 것이 메인 메모리보다 훨씬 빠르므로, 프로세스가 자주 같은 코어에서 실행되면 캐시 미스가 줄어들어 성능이 향상됩니다.
CPU 코어 간 컨텍스트 스위칭 감소:

컨텍스트 스위칭이란 CPU가 다른 프로세스를 실행하기 위해 상태를 변경하는 작업입니다. CPU affinity를 설정하면 프로세스가 동일한 코어에서 계속 실행되므로, 불필요한 컨텍스트 스위칭이 줄어들어 성능이 개선됩니다.
높은 프로세스 수와 컨텍스트 스위칭 비율이 높은 경우 성능 향상이 더 크게 나타날 수 있습니다.
멀티스레딩 성능:

멀티스레딩을 사용하는 애플리케이션에서는 각 스레드가 같은 코어에서 실행되도록 설정하면 스레드 간의 캐시 공유와 메모리 접근 효율성이 향상될 수 있습니다.
NUMA(NON-UNIFORM MEMORY ACCESS) 최적화:

시스템이 NUMA 아키텍처를 사용할 경우, 서로 다른 CPU에 메모리가 분산되어 있습니다. 이때, CPU affinity를 올바르게 설정하면 메모리 접근 지연을 줄일 수 있습니다. 프로세스가 자신의 CPU와 가까운 메모리에 접근할 확률이 높아지기 때문에 성능 향상이 발생합니다.
🔹 성능 향상 추정치
성능 향상의 정도는 시스템 구조와 프로세스의 특성에 따라 다르지만, 일반적인 기대치를 제시할 수 있습니다.

경미한 성능 향상:

시스템이 단일 코어에서 실행되는 경우나 작은 프로세스들일 경우, CPU affinity가 큰 영향을 미치지 않을 수 있습니다. 이런 경우 성능 향상은 몇 퍼센트 내외일 수 있습니다.
중간 정도의 성능 향상:

멀티코어 시스템에서 여러 프로세스가 동시에 실행되고, 각 프로세스가 많은 계산을 수행하는 경우, CPU affinity를 설정하면 10~30% 정도 성능이 향상될 수 있습니다. 이 경우 캐시 지역성과 컨텍스트 스위칭 감소가 중요한 역할을 합니다.
큰 성능 향상:

CPU 코어 간 컨텍스트 스위칭이 많거나 NUMA 시스템에서 작업이 실행되는 경우, CPU affinity를 설정하면 30% 이상의 성능 향상을 기대할 수 있습니다. 특히 병렬 처리가 중요한 시스템에서 큰 효과를 볼 수 있습니다.
🔹 성능 향상을 극대화하는 전략
프로세스의 실행 패턴에 맞게 조정: CPU affinity를 잘 설정하면, 같은 코어에서 계속 실행되도록 하여 캐시 효율을 극대화하고, 컨텍스트 스위칭을 줄여 성능 향상을 얻을 수 있습니다.
CPU 코어 수와 프로세스 수에 비례: CPU 코어 수가 많고, 프로세스가 CPU의 자원을 효율적으로 사용하는 경우 성능 향상이 더 크게 나타날 수 있습니다.
NUMA 시스템에서의 최적화: NUMA 시스템에서는 각 프로세스가 가까운 메모리에 접근하도록 affinity를 설정하는 것이 성능을 크게 향상시킬 수 있습니다.
🔹 결론
CPU affinity 설정은 캐시 지역성과 컨텍스트 스위칭 감소에 의해 성능을 10~30% 정도 향상시킬 수 있습니다. 시스템의 프로세스 수가 많고 멀티코어 시스템에서 실행되는 경우, 특히 NUMA 아키텍처를 사용할 때 성능 향상 효과가 30% 이상 나올 수 있습니다.






# tcp 세션 10개가 붙어있는데 하나의 프로세스가 처리하는게 유리한지 10개의 프로세스가 동시에 처리하는게 유리한지 알수 있어?
TCP 세션 10개가 동시에 연결되어 있을 때, 하나의 프로세스가 이를 처리하는 것이 유리한지, 
아니면 10개의 프로세스가 각각 처리하는 것이 유리한지는 여러 가지 요소에 따라 달라질 수 있습니다. 
이를 결정하려면 다음과 같은 점들을 고려해야 합니다:


1. 프로세스 간 컨텍스트 스위칭 (Context Switching)
여러 프로세스를 사용하면 컨텍스트 스위칭이 발생합니다. 이 작업은 CPU에서 각 프로세스의 상태를 저장하고 복원하는 작업이므로 비용이 발생합니다. 
너무 많은 프로세스를 사용하면 컨텍스트 스위칭에 의한 성능 저하가 발생할 수 있습니다.
하나의 프로세스에서 여러 세션을 처리하면 컨텍스트 스위칭을 피할 수 있고, 성능 효율이 높을 수 있습니다.

2. 멀티코어 활용
만약 시스템에 멀티코어 CPU가 있고, 각 프로세스가 별도의 CPU 코어에서 실행될 수 있다면, 여러 프로세스를 사용하는 것이 병렬 처리를 통해 성능을 향상시킬 수 있습니다.
그러나 프로세스마다 스레드를 사용하는 것이 더 효율적일 수 있습니다. 하나의 프로세스 내에서 멀티스레딩을 활용하는 것이 시스템 자원을 더 효율적으로 사용할 수 있기 때문입니다.

3. IO 병목과 블로킹
TCP 세션을 처리하는 동안, 만약 네트워크 IO가 블로킹되거나 지연이 발생하는 경우, 하나의 프로세스가 모든 세션을 처리하는 것이 비효율적일 수 있습니다. 
비동기 I/O를 사용하거나 멀티프로세스 방식으로 여러 세션을 동시에 처리하는 것이 좋습니다.
select(), poll(), epoll()와 같은 IO 다중화 기법을 사용하면, 하나의 프로세스가 여러 세션을 비동기적으로 처리할 수 있습니다.

4. 메모리와 자원 관리
여러 프로세스가 실행되면 각 프로세스는 자체 메모리 공간을 할당받기 때문에 메모리 오버헤드가 발생할 수 있습니다.
반면, 하나의 프로세스가 여러 세션을 처리하면 메모리 자원을 더 효율적으로 사용할 수 있습니다.

5. 디스크 I/O와 CPU 사용
CPU 집약적 작업을 주로 처리한다면, 여러 프로세스를 사용하는 것이 더 유리할 수 있습니다. 멀티코어 시스템에서 병렬 처리하여 성능을 높일 수 있습니다.
그러나 디스크 I/O 또는 네트워크 I/O가 병목이라면, 하나의 프로세스에서 비동기 방식으로 여러 세션을 처리하는 것이 더 효율적일 수 있습니다.

6. 세션 독립성
각 TCP 세션이 완전히 독립적이라면, 각 프로세스가 하나의 세션을 처리하는 것이 성능 향상에 더 좋을 수 있습니다. 
하지만 세션 간 데이터 공유가 필요하거나, 세션 간 상태 정보를 공유해야 한다면, 하나의 프로세스가 이를 관리하는 것이 더 효율적일 수 있습니다.


결론:
하나의 프로세스가 10개의 TCP 세션을 처리하는 것이 더 효율적일 수 있습니다. 
특히, IO 다중화 기법을 사용하면 여러 세션을 동시에 처리하면서 성능을 최적화할 수 있습니다.
10개의 프로세스가 각각 독립적으로 처리하는 것이 더 유리한 경우는 각 세션이 독립적인 작업을 수행하고, 멀티코어 시스템에서 병렬 처리가 가능할 때입니다. 
그러나 프로세스 간 컨텍스트 스위칭 비용과 메모리 오버헤드를 고려해야 합니다.
따라서 하나의 프로세스가 여러 세션을 처리하는 방식이 비효율적인 IO 처리를 피하고 성능을 최적화할 수 있는 경우가 많지만, 상황에 따라 멀티프로세스 방식도 고려할 수 있습니다.

# 하나의 프로세스가 10개의 세션을 처리하는게 효율적이지만 블록킹 모드라서 시간 지연이 생길수 있지않아?
맞습니다. 하나의 프로세스가 10개의 TCP 세션을 처리할 때 블로킹 모드에서는 성능 문제가 발생할 수 있습니다. 
블로킹 모드에서 네트워크 작업(예: 읽기/쓰기)이 완료될 때까지 프로세스가 대기하게 되는데, 이로 인해 지연이 발생할 수 있습니다. 
예를 들어, 하나의 세션에서 데이터 읽기를 기다리고 있을 때, 다른 세션의 처리가 지연될 수 있습니다. 
이를 해결하기 위해서는 비동기 I/O 또는 멀티스레딩을 사용하는 방법을 고려할 수 있습니다.

1. 비동기 I/O (Non-blocking I/O)
비동기 I/O는 블로킹 없이 작업을 진행할 수 있도록 합니다. 네트워크 작업을 비동기적으로 처리하면, 
하나의 프로세스가 여러 TCP 세션을 동시에 처리하면서 지연을 최소화할 수 있습니다.

select(), poll(), epoll() 등의 I/O 다중화 기법을 사용하여 여러 세션을 동시에 모니터링하고 처리할 수 있습니다. 
이렇게 하면 각 세션에서 발생하는 블로킹 작업을 기다리지 않고 다른 세션을 처리할 수 있습니다.

예를 들어, epoll()을 사용하면 I/O 작업이 준비된 세션만 처리하고, 그 외의 세션은 계속 대기하는 방식으로 동작합니다.


2. 멀티스레딩
하나의 프로세스 내에서 멀티스레드를 사용하면 각 TCP 세션을 별도의 스레드에서 처리할 수 있습니다. 
이렇게 하면 블로킹 작업이 발생한 세션이 다른 세션의 처리를 지연시키지 않도록 할 수 있습니다.

예를 들어, 하나의 스레드가 블로킹 작업을 기다리고 있는 동안 다른 스레드는 다른 세션을 처리할 수 있습니다.

장점:
CPU 리소스를 효과적으로 활용할 수 있습니다.
각 세션을 독립적으로 처리할 수 있습니다.

단점:
스레드 간의 동기화 및 자원 공유에 대한 관리가 필요합니다.
스레드가 너무 많아지면 스레드 생성 비용이 늘어날 수 있습니다.

3. 멀티프로세싱
여러 개의 자식 프로세스가 각 세션을 처리하는 방식도 있습니다. 
각 자식 프로세스는 독립적으로 세션을 처리하므로 하나의 세션에서 블로킹이 발생하더라도 다른 세션에 영향을 미치지 않습니다.

프로세스 간 **IPC (Inter-process Communication)**가 필요할 수 있지만, 독립된 메모리 공간을 사용할 수 있어 메모리 보호가 가능합니다.

장점:
각 프로세스가 독립적이므로 강력한 격리가 가능합니다.
멀티코어 시스템에서 병렬 처리가 가능합니다.

단점:
프로세스 간의 통신 비용이 발생할 수 있습니다.
메모리 오버헤드가 발생할 수 있습니다.

4. 하이브리드 접근 (비동기 + 멀티스레딩)
비동기 I/O와 멀티스레딩을 결합하여 성능을 극대화할 수 있습니다. 
예를 들어, 하나의 스레드는 I/O 다중화를 사용하여 여러 세션을 비동기적으로 처리하고, 각 세션은 하나의 스레드에서 독립적으로 처리될 수 있습니다.

결론:
하나의 프로세스가 10개의 세션을 처리하는 것이 효율적이지만, 블로킹 모드에서는 시간 지연이 발생할 수 있습니다. 
이를 해결하려면 비동기 I/O나 멀티스레딩 또는 멀티프로세싱 기법을 사용하여 성능을 최적화할 수 있습니다.

비동기 I/O: 네트워크 I/O가 블로킹되지 않도록 하여 여러 세션을 효율적으로 처리합니다.
멀티스레딩: 각 세션을 독립적인 스레드로 처리하여 블로킹 영향을 최소화합니다.
멀티프로세싱: 각 세션을 별도의 프로세스로 처리하여 독립적으로 작업을 진행합니다.
이들 방법을 적절히 결합하여 사용하면 블로킹 문제를 해결하고, 성능을 최적화할 수 있습니다.